{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW_aDM0up1nW",
        "outputId": "5772d8f0-e4c8-4224-efea-214bc8354c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "# This command installs the Hugging Face 'transformers' library.\n",
        "# It's a powerful library with many pre-trained AI models including GPT-2.\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the text-generation pipeline function from transformers.\n",
        "# This allows us to use pre-trained models like GPT-2 to generate text.\n",
        "from transformers import pipeline\n",
        "\n",
        "# Import the textwrap module to make long story output cleaner and easier to read.\n",
        "import textwrap\n",
        "\n",
        "# Import random so we can generate random story titles later.\n",
        "import random\n"
      ],
      "metadata": {
        "id": "BCitpHqhqwVk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This dictionary links each \"tone\" to a custom twist or instruction for the AI.\n",
        "# These twists will guide the AI to generate stories in the selected style.\n",
        "twists = {\n",
        "    \"funny\": \"Make it hilarious with unexpected turns and lots of puns.\",\n",
        "    \"emotional\": \"Make it heartwarming and deeply emotional.\",\n",
        "    \"scary\": \"Make it spooky, dark, and terrifying.\",\n",
        "    \"romantic\": \"Make it a sweet, heart-melting romantic tale.\",\n",
        "    \"mystery\": \"Add a suspenseful mystery twist.\",\n",
        "    \"adventure\": \"Make it an exciting and fast-paced adventure story.\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "B0VHmPDUqwE3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A welcome message for user clarity.\n",
        "print(\"üé§ WELCOME TO THE AI STORY GENERATOR üé§\\n\")\n",
        "\n",
        "# Ask the user to enter a starting line for their story.\n",
        "user_input = input(\"Enter your story's starting line: \")\n",
        "\n",
        "# Show the list of tone options so the user can choose.\n",
        "print(\"\\nAvailable tones:\", ', '.join(twists.keys()))\n",
        "\n",
        "# Ask the user to choose one of the available tones.\n",
        "# .lower() ensures it matches our dictionary even if typed in capital letters.\n",
        "tone = input(\"Choose a tone for your story: \").lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQjWpdPqqwB0",
        "outputId": "918e282c-b021-4761-82e0-a94adac7de47"
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé§ WELCOME TO THE AI STORY GENERATOR üé§\n",
            "\n",
            "Enter your story's starting line: As the last human on Mars scanned the red horizon, a strange signal echoed through the dust storm, calling out their name.\n",
            "\n",
            "Available tones: funny, emotional, scary, romantic, mystery, adventure\n",
            "Choose a tone for your story: mystery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the user's tone choice, we fetch the matching twist from the dictionary.\n",
        "# If the tone isn't found, we provide a default twist.\n",
        "style = twists.get(tone, \"Make it engaging and interesting.\")\n",
        "\n",
        "# Combine the user's starting line with the twist to form the full prompt.\n",
        "# This prompt is what we will send to GPT-2.\n",
        "prompt = f\"{user_input}\\n{style}\""
      ],
      "metadata": {
        "id": "gcYqaXGsqv_T"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GPT-2 text generation pipeline.\n",
        "# It will take our prompt and generate a story based on it.\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqssNeUOqv6T",
        "outputId": "1bef58c7-fe46-471f-d63c-633e0124093b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the generator to create a story based on the prompt.\n",
        "# max_length = controls how long the story can be (200‚Äì250 is usually nice).\n",
        "# temperature = controls creativity (higher = more randomness).\n",
        "# num_return_sequences = how many stories to return; we‚Äôre using 1.\n",
        "story_output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=250,          # Replaces max_length\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,\n",
        "    pad_token_id=50256           # Explicit padding token for GPT-2\n",
        ")\n",
        "\n",
        "# Extract only the story text from the result (it returns a list of dicts).\n",
        "story = story_output[0]['generated_text']"
      ],
      "metadata": {
        "id": "_j-_N-CIqv1I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This list has some fun words we can use to generate a random story title.\n",
        "title_words = [\"Secret\", \"Legend\", \"Mystery\", \"Journey\", \"Love\", \"Shadow\", \"Dream\", \"Destiny\"]\n",
        "\n",
        "# We pick a random word from the list and combine it with the chosen tone.\n",
        "# Example: \"The Legend of the Scary Tale\"\n",
        "title = f\"The {random.choice(title_words)} of the {tone.capitalize()} Tale\""
      ],
      "metadata": {
        "id": "av9Hghceqvv1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a clean header with the auto-generated title\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"üìò Title: {title}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Print a label for the story\n",
        "print(\"\\nüìù Generated Story:\\n\")\n",
        "\n",
        "# Use textwrap to break long lines into 80 characters wide for better readability\n",
        "print(textwrap.fill(story, width=80))\n",
        "\n",
        "# Add a nice footer\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚ú® Thank you for using AI Story Generator ‚ú®\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNAuge2tqvqk",
        "outputId": "33de8115-6929-4179-f821-57c434d09fe1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìò Title: The Journey of the Mystery Tale\n",
            "================================================================================\n",
            "\n",
            "üìù Generated Story:\n",
            "\n",
            "As the last human on Mars scanned the red horizon, a strange signal echoed\n",
            "through the dust storm, calling out their name. Add a suspenseful mystery twist.\n",
            "The mystery is one of the best parts of this movie. Even if you do not know that\n",
            "this is a movie, you will at least see that story unfold.\n",
            "\n",
            "================================================================================\n",
            "‚ú® Thank you for using AI Story Generator ‚ú®\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######       OPTION TO Regenerate    ########\n",
        "\n",
        "# Ask the user if they want to try generating a new version of the story\n",
        "retry = input(\"\\nDo you want to regenerate the story with the same input? (yes/no): \").lower()\n",
        "\n",
        "# If yes, we re-generate the story but with slightly higher creativity (temperature = 0.9)\n",
        "if retry == \"yes\":\n",
        "    story_output = generator(prompt, max_length=250, num_return_sequences=1, temperature=0.9)\n",
        "    story = story_output[0]['generated_text']\n",
        "\n",
        "    print(\"\\nüîÅ Regenerated Story:\\n\")\n",
        "    print(textwrap.fill(story, width=80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYhKWpIYqvn5",
        "outputId": "144658e9-2e60-4600-b69b-66a4f76fdb7d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Do you want to regenerate the story with the same input? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RsruvgO1qviv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}